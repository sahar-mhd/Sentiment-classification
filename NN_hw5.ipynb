{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eak6PD4SMFqA",
        "outputId": "1e88c66f-9288-40a2-9e91-a7f7da1cedc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UZ1HFWsughtw"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import shutil\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RCnNl8CtMuui",
        "outputId": "0c4e228d-1e12-497c-bc86-5e65a20b6ae9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Gift_Cards_5.json.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "shutil.copyfile(\"/content/drive/MyDrive/NN/hw5/Gift_Cards_5.json.gz\", \"/content/Gift_Cards_5.json.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BDNLK7-hNukx"
      },
      "outputs": [],
      "source": [
        "with gzip.open('/content/Gift_Cards_5.json.gz', 'rb') as f_in:\n",
        "    with open('/content/Gift_Cards_5.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "094DJ7gUPBce"
      },
      "outputs": [],
      "source": [
        "# Open the file and read lines\n",
        "data = []\n",
        "with open('Gift_Cards_5.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            data.append(json.loads(line))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e}\")\n",
        "\n",
        "# Now 'data' contains a list of dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5zJElbO9P1gA"
      },
      "outputs": [],
      "source": [
        "text = []\n",
        "labels = []\n",
        "for i in range(len(data)):\n",
        "    if 'reviewText' in data[i]:\n",
        "      text.append(data[i]['reviewText'])\n",
        "      labels.append(data[i]['overall'])\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5vWR72fTeP0",
        "outputId": "dd02e994-7540-44a0-bba7-23a623ff4e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another great gift. 5.0\n"
          ]
        }
      ],
      "source": [
        "print(text[0],labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZhtncNh_b92Z"
      },
      "outputs": [],
      "source": [
        "max_length=0\n",
        "for i in range(len(text)):\n",
        "  length = len(text[i])\n",
        "  if(length>max_length):\n",
        "    max_length=length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pKKJpsTCTq9o"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "max_sequence_length = max_length\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEbcyghkiuHf",
        "outputId": "118e07fa-7874-495e-ed60-763abe3cd32b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0,   0,   0, ..., 224,  10,   1], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKa_YXfqUAFA",
        "outputId": "eb5372c2-cf90-467b-b116-df6029c0218a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "75/75 [==============================] - 136s 2s/step - loss: 0.4073 - accuracy: 0.9132 - val_loss: 0.3522 - val_accuracy: 0.9226\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 121s 2s/step - loss: 0.3200 - accuracy: 0.9266 - val_loss: 0.3301 - val_accuracy: 0.9226\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e589273190>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(units=128, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=2, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hpOho2MgPL1",
        "outputId": "090118bc-93c3-4274-e8a2-b25dca1d8452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "75/75 [==============================] - 644s 8s/step - loss: 0.4416 - accuracy: 0.9153 - val_loss: 0.3407 - val_accuracy: 0.9226\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 625s 8s/step - loss: 0.3064 - accuracy: 0.9266 - val_loss: 0.3299 - val_accuracy: 0.9226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x793796fe3a00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=2, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-5v2LrJwiBiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598bcec4-6200-4f93-d52c-64d108a9bd93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "75/75 [==============================] - 777s 10s/step - loss: 0.4303 - accuracy: 0.9233 - val_loss: 0.3373 - val_accuracy: 0.9226\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 768s 10s/step - loss: 0.3330 - accuracy: 0.9266 - val_loss: 0.3402 - val_accuracy: 0.9226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cba94e11450>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(units=64))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=2, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GsQZnyOHg5Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1430dc-6c6b-419a-d04a-68512b6f4724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "75/75 [==============================] - 532s 7s/step - loss: 0.5079 - accuracy: 0.9165 - val_loss: 0.3323 - val_accuracy: 0.9226\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 522s 7s/step - loss: 0.2767 - accuracy: 0.9266 - val_loss: 0.3111 - val_accuracy: 0.9226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cba95830730>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(GRU(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=2, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JON7q7tbjx01"
      },
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YowEROiPj--N"
      },
      "outputs": [],
      "source": [
        "# Separate class 2 and 4 samples\n",
        "class_2_indices = np.where(y == 1)[0]\n",
        "class_4_indices = np.where(y == 3)[0]\n",
        "\n",
        "# Combine indices of class 2 and 4 samples\n",
        "test_indices = np.concatenate((class_2_indices, class_4_indices))\n",
        "\n",
        "# Remove these indices from the training data\n",
        "X_train = np.delete(X, test_indices, axis=0)\n",
        "y_train = np.delete(y, test_indices, axis=0)\n",
        "\n",
        "\n",
        "# Add class 2 and 4 samples to the test set\n",
        "X_test = X[test_indices]\n",
        "y_test = y[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDSmfxQ1kzgo",
        "outputId": "f789ae2d-d6b3-4f1c-d274-7e3040fb6c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "70/70 [==============================] - 112s 2s/step - loss: 0.1627 - accuracy: 0.9781 - val_loss: 0.1156 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 118s 2s/step - loss: 0.6645 - accuracy: 0.9009 - val_loss: 0.1209 - val_accuracy: 0.9786\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e58951bfd0>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(units=128, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0FoWm5QlZCs",
        "outputId": "0f3660e4-6d6c-4ca2-c9b5-b02e5e0ff6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 2s 261ms/step\n",
            "acc: 0.00%\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print('acc: {:.2%}'.format(np.mean(y_pred == y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7MTI6DWBN9f",
        "outputId": "5416195c-fb3e-4169-e9c6-1d5c075c3ca1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "70/70 [==============================] - 358s 5s/step - loss: 0.2565 - accuracy: 0.9688 - val_loss: 0.1160 - val_accuracy: 0.9786\n",
            "Epoch 2/2\n",
            "70/70 [==============================] - 356s 5s/step - loss: 0.1104 - accuracy: 0.9808 - val_loss: 0.1128 - val_accuracy: 0.9786\n",
            "6/6 [==============================] - 4s 590ms/step\n",
            "acc: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print('acc: {:.2%}'.format(np.mean(y_pred == y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMNTS3LcAuED",
        "outputId": "f94779ad-33b8-4c81-c3a7-782d2b854d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-26 20:10:35--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Musical_Instruments.json.gz\n",
            "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
            "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232750177 (222M) [application/x-gzip]\n",
            "Saving to: ‘Musical_Instruments.json.gz’\n",
            "\n",
            "Musical_Instruments 100%[===================>] 221.97M  4.24MB/s    in 57s     \n",
            "\n",
            "2024-05-26 20:11:33 (3.88 MB/s) - ‘Musical_Instruments.json.gz’ saved [232750177/232750177]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Musical_Instruments.json.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbQxySk8gZk4"
      },
      "outputs": [],
      "source": [
        "with gzip.open('/content/Musical_Instruments.json.gz', 'rb') as f_in:\n",
        "    with open('/content/Musical_Instruments.json', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5DpiNCLhPEL"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open('Musical_Instruments.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            data.append(json.loads(line))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e}\")\n",
        "text = []\n",
        "labels = []\n",
        "for i in range(len(data)):\n",
        "    if 'reviewText' in data[i]:\n",
        "      text.append(data[i]['reviewText'])\n",
        "      labels.append(data[i]['overall'])\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGiMyE7FTv2E",
        "outputId": "29593a40-3243-4f7c-b26e-1f426aed75f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crocheting for Dummies by Karen Manthey & Susan Brittain is a wonderfully thorough and very informative book for anyone wanting to learn to crochet and or wanting to freshen up their skills.\n",
            "\n",
            "The book reads like a storybook in paragraph form.  Everything is explained in great detail from choosing yarns and hooks, to how to work a large array of crochet stitches, to how to read a pattern, right down to how to care for ones crocheted items.\n",
            "\n",
            "The stitch drawings are clear and expertly done making learning new stitches so much easier.\n",
            "\n",
            "The book has both a contents page and an index for easy referral.  I especially liked the fact that an index was included.  So many crochet books do not include this.  The index makes it very easy to find information on a particular topic quickly.\n",
            "\n",
            "The recommendations for people just learning to crochet are fantastic.  This book wasn't out when I learned to crochet and I learned the hard way about many of the pit falls this book helps one to avoid.  For instance they recommend one start out with a size H-8 crochet hook and a light colored worsted weight yarn.  I learned with a B-1 hook and a fingering weight yarn.  After 2 whole days of crocheting it was 36\" long and 1.5\" tall.  I was trying to make a baby blanket for my doll (which never got made).\n",
            "\n",
            "The book contains humor, not just in the cartoons but in the instructions as well which makes for very entertaining reading while one learns a new craft.  I always appreciate having a teacher with a sense of humor!\n",
            "\n",
            "A good sampling of designs is included so that one can try out their skills.  These include sweaters, an afghan, doilies, hot pads, pillow, scarves, floral motifs, and bandanas.\n",
            "\n",
            "I am a crochet designer and I read the book cover to cover like a storybook while on vacation this past week.  I thoroughly enjoyed it and learned a few things as well.  I would highly recommend this book to anyone interested in the art of crochet. 5.0\n"
          ]
        }
      ],
      "source": [
        "print(text[0],labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVXY73Kpi1M3",
        "outputId": "97b6cfb1-d848-4c21-ff18-6170ea1b7082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1511675"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHZaewAhkVn0"
      },
      "outputs": [],
      "source": [
        "text_total = text\n",
        "labels_total = labels\n",
        "\n",
        "text = text[:5000]\n",
        "labels = labels[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELfxvMpwlcbI",
        "outputId": "0a83160f-2726-4ac8-b509-02a6eb7e7545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6LU9OjCnYf1"
      },
      "outputs": [],
      "source": [
        "max_length=0\n",
        "for i in range(len(text)):\n",
        "  length = len(text[i])\n",
        "  if(length>max_length):\n",
        "    max_length=length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB6ZtkgaifiZ"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "max_sequence_length = max_length\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVGnyFrFCIqA"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Separate class 2 and 4 samples\n",
        "class_2_indices = np.where(y == 1)[0]\n",
        "class_4_indices = np.where(y == 3)[0]\n",
        "\n",
        "# Combine indices of class 2 and 4 samples\n",
        "test_indices = np.concatenate((class_2_indices, class_4_indices))\n",
        "\n",
        "# Remove these indices from the training data\n",
        "X_train = np.delete(X, test_indices, axis=0)\n",
        "y_train = np.delete(y, test_indices, axis=0)\n",
        "\n",
        "# Add class 2 and 4 samples to the test set\n",
        "X_test = X[test_indices]\n",
        "y_test = y[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KlsF0P9fdGs",
        "outputId": "39bbf1a1-a4ee-40df-ead0-e635b751f638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1102"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rptM0O06nNMm",
        "outputId": "016f8909-0b1b-499f-cbfd-69e1c5cd3cf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5369"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ju4LdVqCw3m",
        "outputId": "aa2c1e85-cbb5-45a5-b59b-fce999883f44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "195/195 [==============================] - 4515s 23s/step - loss: 0.8035 - accuracy: 0.7248 - val_loss: 0.5044 - val_accuracy: 0.8487\n",
            "35/35 [==============================] - 58s 2s/step\n",
            "acc: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=7000, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=1, batch_size=16, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print('acc: {:.2%}'.format(np.mean(y_pred == y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O1guGKISJg1",
        "outputId": "109aa677-e905-475d-8f3d-0146e3f04aa0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0,\n",
              "       0, 4, 4, 4, 0, 0, 4, 4])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcpQLH9ZMuPu",
        "outputId": "feb7b106-538c-4ec7-f59c-b0967c70b541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49/49 [==============================] - 1051s 21s/step - loss: 1.0089 - accuracy: 0.7091 - val_loss: 0.5867 - val_accuracy: 0.8359\n",
            "35/35 [==============================] - 43s 1s/step\n",
            "acc: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=1, batch_size= 64, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print('acc: {:.2%}'.format(np.mean(y_pred == y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate class 2 and 4 samples\n",
        "class_1_indices = np.where(y == 0)[0]\n",
        "# class_4_indices = np.where(y == 3)[0]\n",
        "\n",
        "# Combine indices of class 2 and 4 samples\n",
        "# test_indices = np.concatenate((class_2_indices, class_4_indices))\n",
        "test_indices = class_1_indices\n",
        "\n",
        "# Remove these indices from the training data\n",
        "X_train = np.delete(X, test_indices, axis=0)\n",
        "y_train = np.delete(y, test_indices, axis=0)\n",
        "\n",
        "\n",
        "# Add class 2 and 4 samples to the test set\n",
        "X_test = X[test_indices]\n",
        "y_test = y[test_indices]"
      ],
      "metadata": {
        "id": "mkI0GCZIKpsE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=False, kernel_regularizer=l2(0.01))))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax', kernel_regularizer=l2(0.01)))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_D545ebKv1r",
        "outputId": "85f7c100-b810-4887-cd32-dfa4277d16c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 472s 3s/step - loss: 1.0757 - accuracy: 0.9274 - val_loss: 0.4328 - val_accuracy: 0.9253\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 433s 3s/step - loss: 0.3604 - accuracy: 0.9346 - val_loss: 0.3619 - val_accuracy: 0.9253\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 433s 3s/step - loss: 0.3327 - accuracy: 0.9346 - val_loss: 0.3499 - val_accuracy: 0.9253\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 432s 3s/step - loss: 0.3244 - accuracy: 0.9346 - val_loss: 0.3428 - val_accuracy: 0.9253\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 433s 3s/step - loss: 0.3131 - accuracy: 0.9346 - val_loss: 0.3389 - val_accuracy: 0.9253\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 434s 3s/step - loss: 0.3127 - accuracy: 0.9346 - val_loss: 0.3354 - val_accuracy: 0.9253\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 428s 3s/step - loss: 0.3099 - accuracy: 0.9346 - val_loss: 0.3318 - val_accuracy: 0.9253\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 440s 3s/step - loss: 0.3059 - accuracy: 0.9346 - val_loss: 0.3388 - val_accuracy: 0.9253\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 446s 3s/step - loss: 0.3079 - accuracy: 0.9346 - val_loss: 0.3331 - val_accuracy: 0.9253\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.3013 - accuracy: 0.9346 - val_loss: 0.3281 - val_accuracy: 0.9253\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 427s 3s/step - loss: 0.3065 - accuracy: 0.9346 - val_loss: 0.3279 - val_accuracy: 0.9253\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 429s 3s/step - loss: 0.3024 - accuracy: 0.9346 - val_loss: 0.3313 - val_accuracy: 0.9253\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 430s 3s/step - loss: 0.3094 - accuracy: 0.9346 - val_loss: 0.3288 - val_accuracy: 0.9253\n",
            "Epoch 14/20\n",
            "148/148 [==============================] - 428s 3s/step - loss: 0.3023 - accuracy: 0.9346 - val_loss: 0.3282 - val_accuracy: 0.9253\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cba8595c400>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print('acc: {:.2%}'.format(np.mean(y_pred == y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaZHbEyTK_6z",
        "outputId": "ae464795-2b9f-48d1-ed48-53d306b4dd59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "acc: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvZOJNs2ouFb",
        "outputId": "157ead21-1a41-4aa0-8acf-905a96312dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-01 18:28:33--  https://huggingface.co/datasets/scikit-learn/imdb/resolve/main/IMDB%20Dataset.csv\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.37, 3.163.189.74, 3.163.189.114, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/77/fa/77fa70b48eef1c98bf08d7b3e43b710623c24c69b4f78d4484f43c3361e9d2af/dfc447764f82be365fa9c2beef4e8df89d3919e3da95f5088004797d79695aa2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27IMDB%2520Dataset.csv%3B+filename%3D%22IMDB+Dataset.csv%22%3B&response-content-type=text%2Fcsv&Expires=1717525713&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzUyNTcxM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83Ny9mYS83N2ZhNzBiNDhlZWYxYzk4YmYwOGQ3YjNlNDNiNzEwNjIzYzI0YzY5YjRmNzhkNDQ4NGY0M2MzMzYxZTlkMmFmL2RmYzQ0Nzc2NGY4MmJlMzY1ZmE5YzJiZWVmNGU4ZGY4OWQzOTE5ZTNkYTk1ZjUwODgwMDQ3OTdkNzk2OTVhYTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=t71o4bYLouC3favhJw%7EMKOOCPvt6T7%7EdIeGZJxeWK-WeCM3H3%7EpRbFWZNDX5MjvAe9P7cQGAwDzfVavZ1TNkG-bMYbjuQMqNF2anR9t7-x6zc7WRhOFc%7Ek-D%7EihjL2iwZOqeoojQmzE1vs%7Eocp5CUJKybdyP3-4r58fSKwHhDA8utgIaYWT35XtDCQvicmezRiL9-h-kO8lx90vpGt9ZrXLGFOG4IqwT7WXzIdUgfTm2YfLvcb0aZdr31qCn2nqrAPjtWmX4dfZIvQW7aNiRrhKext%7E0fmLU9-rnu2n9s0FaN5JHIlBToZCWyAK9OXMs8K7hf6P3NZt6NKiC0Pjc2A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-06-01 18:28:33--  https://cdn-lfs.huggingface.co/repos/77/fa/77fa70b48eef1c98bf08d7b3e43b710623c24c69b4f78d4484f43c3361e9d2af/dfc447764f82be365fa9c2beef4e8df89d3919e3da95f5088004797d79695aa2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27IMDB%2520Dataset.csv%3B+filename%3D%22IMDB+Dataset.csv%22%3B&response-content-type=text%2Fcsv&Expires=1717525713&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzUyNTcxM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83Ny9mYS83N2ZhNzBiNDhlZWYxYzk4YmYwOGQ3YjNlNDNiNzEwNjIzYzI0YzY5YjRmNzhkNDQ4NGY0M2MzMzYxZTlkMmFmL2RmYzQ0Nzc2NGY4MmJlMzY1ZmE5YzJiZWVmNGU4ZGY4OWQzOTE5ZTNkYTk1ZjUwODgwMDQ3OTdkNzk2OTVhYTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=t71o4bYLouC3favhJw%7EMKOOCPvt6T7%7EdIeGZJxeWK-WeCM3H3%7EpRbFWZNDX5MjvAe9P7cQGAwDzfVavZ1TNkG-bMYbjuQMqNF2anR9t7-x6zc7WRhOFc%7Ek-D%7EihjL2iwZOqeoojQmzE1vs%7Eocp5CUJKybdyP3-4r58fSKwHhDA8utgIaYWT35XtDCQvicmezRiL9-h-kO8lx90vpGt9ZrXLGFOG4IqwT7WXzIdUgfTm2YfLvcb0aZdr31qCn2nqrAPjtWmX4dfZIvQW7aNiRrhKext%7E0fmLU9-rnu2n9s0FaN5JHIlBToZCWyAK9OXMs8K7hf6P3NZt6NKiC0Pjc2A__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.94.23, 108.138.94.25, 108.138.94.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.94.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66212309 (63M) [text/csv]\n",
            "Saving to: ‘IMDB Dataset.csv’\n",
            "\n",
            "IMDB Dataset.csv    100%[===================>]  63.14M  42.0MB/s    in 1.5s    \n",
            "\n",
            "2024-06-01 18:28:35 (42.0 MB/s) - ‘IMDB Dataset.csv’ saved [66212309/66212309]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://huggingface.co/datasets/scikit-learn/imdb/resolve/main/IMDB%20Dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzvDUY8F7DV",
        "outputId": "4d673c13-12ee-4303-edbb-cf5a26ccfe1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "xVrWa_pk2I1v",
        "outputId": "5aea075c-cdb5-4579-8900-46817c6b423c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "zn-dKLNt9nnQ",
        "outputId": "6d5866e4-8921-4447-c79e-f926b8a4455a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGzAv2eb2a6B",
        "outputId": "24b5474d-7708-4375-b4dd-90db036d4742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.iloc[:3000,:]"
      ],
      "metadata": {
        "id": "yWWnJ8Nv29o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "labels = []\n",
        "for i in range(len(data)):\n",
        "    # if 'reviewText' in data[i]:\n",
        "      text.append(data['review'][i])\n",
        "      if(data['sentiment'][i]=='positive'):\n",
        "        labels.append(1)\n",
        "      elif(data['sentiment'][i]=='negative'):\n",
        "        labels.append(0)\n",
        "    # else:\n",
        "    #   continue"
      ],
      "metadata": {
        "id": "Fq5DVKAS2W_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFWrJN0_-_ti",
        "outputId": "7c914d37-e978-43f6-85b6-03f9aec8efa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1761"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XbrEW4s6wMF",
        "outputId": "8dcec3f3-7ede-48fa-d34c-efac1d3ccfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0], text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4sxq_uT3QY5",
        "outputId": "0bfd8fd4-1638-4e2c-9115-e983ab65a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=0\n",
        "for i in range(len(text)):\n",
        "  length = len(text[i])\n",
        "  if(length>max_length):\n",
        "    max_length=length"
      ],
      "metadata": {
        "id": "RZpJ8yiB3u3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "max_sequence_length = 200\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "KhMHkw0-3zaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqXxvyjJ9gG1",
        "outputId": "e27e2b28-6d66-4fe7-e382-96b23aed7674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8180"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAEWiLqE_PH4",
        "outputId": "54f8533f-2612-438a-de42-404f782a3048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1761"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=False, kernel_regularizer=l2(0.01))))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=16, validation_split=0.2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lob_oqU2G-Pz",
        "outputId": "9440aa10-9540-45af-92ae-7bc579a7fbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "150/150 [==============================] - 74s 129ms/step - loss: 1.2395 - accuracy: 0.5067 - val_loss: 0.7256 - val_accuracy: 0.4800\n",
            "Epoch 2/20\n",
            "150/150 [==============================] - 12s 78ms/step - loss: 0.7011 - accuracy: 0.5346 - val_loss: 0.6951 - val_accuracy: 0.4800\n",
            "Epoch 3/20\n",
            "150/150 [==============================] - 7s 45ms/step - loss: 0.6877 - accuracy: 0.5854 - val_loss: 0.6713 - val_accuracy: 0.6400\n",
            "Epoch 4/20\n",
            "150/150 [==============================] - 5s 37ms/step - loss: 0.6512 - accuracy: 0.6900 - val_loss: 0.6367 - val_accuracy: 0.6983\n",
            "Epoch 5/20\n",
            "150/150 [==============================] - 5s 33ms/step - loss: 0.4202 - accuracy: 0.8625 - val_loss: 0.6105 - val_accuracy: 0.7183\n",
            "Epoch 6/20\n",
            "150/150 [==============================] - 5s 33ms/step - loss: 0.2680 - accuracy: 0.9212 - val_loss: 0.5728 - val_accuracy: 0.7333\n",
            "Epoch 7/20\n",
            "150/150 [==============================] - 4s 26ms/step - loss: 0.2567 - accuracy: 0.9317 - val_loss: 0.5902 - val_accuracy: 0.7483\n",
            "Epoch 8/20\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.1861 - accuracy: 0.9667 - val_loss: 0.6071 - val_accuracy: 0.7800\n",
            "Epoch 9/20\n",
            "150/150 [==============================] - 5s 34ms/step - loss: 0.1336 - accuracy: 0.9825 - val_loss: 0.7283 - val_accuracy: 0.7767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f902250cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}